# Load Testing Guide

**Session 18 - Phase 3: Comprehensive Load Testing**

This directory contains the complete load testing infrastructure for the Radeon RX 580 AI Platform API using Locust.

---

## ğŸš€ Quick Start

### Option 1: Command Line (Automated)

```bash
# Run light load test
./scripts/run_load_tests.sh light

# Run all scenarios
./scripts/run_load_tests.sh all

# Analyze results
python scripts/analyze_load_results.py results/load_tests
```

### Option 2: Web UI (Interactive)

```bash
# Start Locust Web UI
locust -f tests/load/locustfile.py --host http://localhost:8000

# Open browser: http://localhost:8089
# Configure users and spawn rate
# Start swarming!
```

### Option 3: Docker (Containerized)

```bash
# Start API + Locust
docker-compose --profile loadtest up -d

# Open browser: http://localhost:8089
# Run tests via Web UI

# Stop
docker-compose --profile loadtest down
```

---

## ğŸ“‹ Available Scenarios

| Scenario | Users | Spawn Rate | Duration | Purpose |
|----------|-------|------------|----------|---------|
| **light** | 10 | 2/s | 5m | Baseline performance |
| **medium** | 50 | 10/s | 10m | Normal production load |
| **heavy** | 200 | 20/s | 15m | Peak traffic & stress |
| **spike** | 500 | 100/s | 5m | Sudden traffic spike |
| **all** | - | - | ~45m | Sequential execution |
| **custom** | ? | ? | ? | Interactive config |

---

## ğŸ“Š What Gets Tested

### Endpoints Covered

âœ… **Health Check**: `/health`  
âœ… **Metrics**: `/metrics`  
âœ… **Model List**: `/models`  
âœ… **Model Load**: `/models/load`  
âœ… **Single Inference**: `/inference`  
âœ… **Batch Inference**: `/inference/batch`

### Input Variations

- **Small**: (1, 3, 224, 224) - ResNet-style images
- **Medium**: (1, 512) - BERT-style sequences
- **Large**: (1, 3, 512, 512) - High-res images
- **Batches**: 2, 4, 8 items

### Metrics Collected

**Performance**:
- Response times (avg, P50, P95, P99)
- Throughput (requests/sec)
- Min/Max latency

**Reliability**:
- Success rate
- Error rate by endpoint
- Failure types

**System**:
- CPU/RAM/GPU usage (via Prometheus)
- Queue sizes
- Concurrent connections

---

## ğŸ”§ Configuration

### Locust File Structure

```python
# tests/load/locustfile.py

# Task Sets (scenario groups)
- HealthCheckTasks      # Basic health checks
- ModelManagementTasks  # Model operations
- InferenceTasks        # Single inference
- MixedWorkloadTasks    # Realistic mix

# User Classes (load profiles)
- LightLoadUser         # 10 users, slow pace
- MediumLoadUser        # 50 users, normal pace
- HeavyLoadUser         # 200 users, fast pace
- SpikeTestUser         # 500 users, very fast
```

### Custom Test

```bash
# CLI mode
locust -f tests/load/locustfile.py \
       --host http://localhost:8000 \
       --users 100 \
       --spawn-rate 10 \
       --run-time 5m \
       --headless \
       --csv results/my_test

# With specific tags
locust -f tests/load/locustfile.py \
       --host http://localhost:8000 \
       --tags inference,heavy_load \
       --headless
```

---

## ğŸ“ˆ Analysis & Reports

### Automatic Analysis

```bash
# Analyze latest test
python scripts/analyze_load_results.py results/load_tests

# Specific test
python scripts/analyze_load_results.py results/load_tests/20260119_143022_light_stats.csv

# Export JSON for CI/CD
python scripts/analyze_load_results.py results/load_tests --json analysis.json
```

### What You Get

**Console Report**:
```
ğŸ“Š LOAD TEST ANALYSIS REPORT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ˆ OVERALL SUMMARY
  Total Requests:     10,245
  Total Failures:     12
  Error Rate:         0.12% (Excellent)
  Throughput:         34.15 req/s
  Avg Response Time:  45.23ms
  P50:                42.10ms
  P95:                78.50ms (Excellent)
  P99:                125.30ms

ğŸ“‹ ENDPOINT BREAKDOWN
/health
  Requests: 2,048 | Failures: 0 | Error: 0.00%
  Avg: 12.3ms | P95: 18.2ms | P99: 24.5ms
  Grade: Excellent (performance), Excellent (reliability)

/inference [small]
  Requests: 5,120 | Failures: 8 | Error: 0.16%
  Avg: 65.4ms | P95: 98.7ms | P99: 145.2ms
  Grade: Good (performance), Excellent (reliability)

ğŸ” IDENTIFIED BOTTLENECKS
  (None - system performing well)

ğŸ’¡ RECOMMENDATIONS
  âœ… Performance looks good! Consider:
     - Monitoring in production environment
     - Setting up automated performance regression tests
     - Testing with realistic traffic patterns
```

**HTML Report**:
- Visual charts and graphs
- Request distribution
- Response time percentiles
- Error breakdown
- Auto-generated by Locust

**JSON Export**:
```json
{
  "timestamp": "2026-01-19T14:30:22",
  "analysis": {
    "summary": {
      "total_requests": 10245,
      "error_rate": 0.12,
      "p95": 78.5,
      "performance_grade": "Excellent"
    },
    ...
  },
  "bottlenecks": [],
  "recommendations": [...]
}
```

---

## ğŸ¯ Best Practices

### Before Testing

1. âœ… Ensure API is running and healthy
2. âœ… Start Prometheus/Grafana for resource monitoring
3. âœ… Clear previous test results if needed
4. âœ… Note baseline performance

### During Testing

1. ğŸ“Š Monitor Grafana dashboards
2. ğŸ“Š Watch Locust Web UI stats
3. ğŸ“Š Check API logs for errors
4. ğŸ“Š Observe system resources

### After Testing

1. ğŸ“ˆ Analyze results immediately
2. ğŸ“ˆ Compare with previous tests
3. ğŸ“ˆ Identify trends and regressions
4. ğŸ“ˆ Document findings
5. ğŸ“ˆ Implement optimizations

---

## ğŸ› Troubleshooting

### "Connection refused"
â†’ API not running. Start with: `docker-compose up -d api`

### "Too many open files"
â†’ Increase system limits: `ulimit -n 65536`

### "API becomes unresponsive"
â†’ Load too high. Reduce users or increase API resources

### "No results generated"
â†’ Check permissions: `mkdir -p results/load_tests && chmod 755 results/load_tests`

### "Import errors in locustfile.py"
â†’ Install dependencies: `pip install locust numpy`

---

## ğŸ“ Files

```
tests/load/
â”œâ”€â”€ locustfile.py           # Main test suite (440+ lines)
â”‚   â”œâ”€â”€ Config constants
â”‚   â”œâ”€â”€ Utility functions
â”‚   â”œâ”€â”€ Task sets (4 groups)
â”‚   â”œâ”€â”€ User classes (4 profiles)
â”‚   â””â”€â”€ Event handlers
â”‚
â”œâ”€â”€ scenarios/              # Future: Separate scenario files
â”‚   â””â”€â”€ (empty for now)
â”‚
â””â”€â”€ README.md              # This file
```

---

## ğŸ“š Learn More

**Locust Documentation**: https://docs.locust.io/  
**Performance Testing Guide**: See SESSION_18_PHASE_3_COMPLETE.md  
**API Documentation**: http://localhost:8000/docs

---

## ğŸ“ Example Workflow

```bash
# 1. Start the stack
docker-compose up -d api
docker-compose --profile monitoring up -d

# 2. Open monitoring
open http://localhost:3000  # Grafana

# 3. Run baseline test
./scripts/run_load_tests.sh light

# 4. Analyze results
python scripts/analyze_load_results.py results/load_tests

# 5. Run stress test
./scripts/run_load_tests.sh heavy

# 6. Compare and optimize
python scripts/analyze_load_results.py results/load_tests

# 7. Run spike test
./scripts/run_load_tests.sh spike

# 8. Final analysis
python scripts/analyze_load_results.py results/load_tests --json final_report.json
```

---

**Happy Load Testing! ğŸš€**

Quality: 9.8/10 | Session: 18 | Phase: 3/4
