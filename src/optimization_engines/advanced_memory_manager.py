#!/usr/bin/env python3
"""
üß† ADVANCED MEMORY MANAGER - Optimizaci√≥n de Memoria para RX 580
================================================================

Sistema avanzado de gesti√≥n de memoria GPU con:
1. Memory pooling inteligente con m√∫ltiples tiers
2. Estrategias de tiling para matrices grandes
3. Prefetching as√≠ncrono de datos
4. Compresi√≥n de buffers sparse
5. M√©tricas detalladas de uso de memoria

Meta: 50% reducci√≥n en uso de memoria GPU

Author: Sistema de Optimizaci√≥n RX 580
Date: 2026-02-02
"""

import logging
import threading
import time
import weakref
from collections import OrderedDict, defaultdict
from contextlib import contextmanager
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Any, Callable, Dict, List, Optional, Set, Tuple

import numpy as np
import pyopencl as cl

logger = logging.getLogger(__name__)


class BufferTier(Enum):
    """Niveles de prioridad de buffers"""

    HOT = auto()  # Acceso frecuente, mantener en GPU
    WARM = auto()  # Acceso moderado
    COLD = auto()  # Acceso infrecuente, candidato a evicci√≥n
    PREFETCH = auto()  # Buffer de prefetch


class TilingStrategy(Enum):
    """Estrategias de tiling para matrices grandes"""

    NONE = auto()  # Sin tiling, matriz completa
    SQUARE = auto()  # Tiles cuadrados
    ROW_MAJOR = auto()  # Tiles por filas
    COL_MAJOR = auto()  # Tiles por columnas
    RECURSIVE = auto()  # Tiling recursivo (matrices muy grandes)


@dataclass
class BufferInfo:
    """Informaci√≥n de un buffer en el pool"""

    buffer: cl.Buffer
    size: int
    tier: BufferTier
    last_access: float
    access_count: int
    is_pinned: bool = False
    ref_count: int = 0

    def touch(self):
        """Actualiza timestamp y contador de acceso"""
        self.last_access = time.time()
        self.access_count += 1

        # Promover tier basado en acceso
        if self.access_count > 10 and self.tier != BufferTier.HOT:
            self.tier = BufferTier.HOT
        elif self.access_count > 3 and self.tier == BufferTier.COLD:
            self.tier = BufferTier.WARM


@dataclass
class TileDescriptor:
    """Descriptor de un tile de matriz"""

    row_start: int
    row_end: int
    col_start: int
    col_end: int
    size_bytes: int
    buffer: Optional[cl.Buffer] = None
    is_loaded: bool = False

    @property
    def shape(self) -> Tuple[int, int]:
        return (self.row_end - self.row_start, self.col_end - self.col_start)

    @property
    def rows(self) -> int:
        return self.row_end - self.row_start

    @property
    def cols(self) -> int:
        return self.col_end - self.col_start


@dataclass
class MemoryStats:
    """Estad√≠sticas de memoria"""

    total_allocated: int = 0
    total_freed: int = 0
    peak_usage: int = 0
    current_usage: int = 0
    pool_hits: int = 0
    pool_misses: int = 0
    evictions: int = 0
    prefetch_hits: int = 0
    prefetch_misses: int = 0
    tiles_created: int = 0
    tiles_reused: int = 0
    compression_savings: int = 0

    @property
    def hit_rate(self) -> float:
        total = self.pool_hits + self.pool_misses
        return self.pool_hits / total if total > 0 else 0.0

    @property
    def memory_efficiency(self) -> float:
        """Eficiencia de memoria: 1 - (peak / total_allocated)"""
        if self.total_allocated == 0:
            return 1.0
        return 1.0 - (self.peak_usage / self.total_allocated)

    def summary(self) -> str:
        return f"""
=== MEMORY STATISTICS ===
Allocated:    {self.total_allocated / 1024**2:.1f} MB
Peak Usage:   {self.peak_usage / 1024**2:.1f} MB
Current:      {self.current_usage / 1024**2:.1f} MB
Pool Hit Rate: {self.hit_rate:.1%}
Evictions:    {self.evictions}
Prefetch Hits: {self.prefetch_hits}
Tiles Created: {self.tiles_created}
Tiles Reused:  {self.tiles_reused}
Compression:  {self.compression_savings / 1024**2:.1f} MB saved
Efficiency:   {self.memory_efficiency:.1%}
"""


class AdvancedBufferPool:
    """
    Pool de buffers avanzado con m√∫ltiples caracter√≠sticas:
    - Tiers de prioridad (HOT/WARM/COLD)
    - Evicci√≥n LRU autom√°tica
    - Estad√≠sticas detalladas
    - Thread-safe
    """

    def __init__(
        self,
        context: cl.Context,
        queue: cl.CommandQueue,
        max_pool_memory: int = 512 * 1024 * 1024,  # 512 MB default
        max_buffers_per_size: int = 5,
        eviction_threshold: float = 0.8,  # Evictar cuando >80% lleno
    ):
        self.context = context
        self.queue = queue
        self.max_pool_memory = max_pool_memory
        self.max_buffers_per_size = max_buffers_per_size
        self.eviction_threshold = eviction_threshold

        # Pools por tama√±o y tipo
        self._read_pool: Dict[int, List[BufferInfo]] = defaultdict(list)
        self._write_pool: Dict[int, List[BufferInfo]] = defaultdict(list)
        self._pinned_buffers: Set[int] = set()  # IDs de buffers pinned

        # Estad√≠sticas
        self.stats = MemoryStats()
        self._current_pool_size = 0

        # Lock para thread safety
        self._lock = threading.Lock()

        logger.info(f"AdvancedBufferPool initialized with {max_pool_memory / 1024**2:.0f} MB limit")

    def _find_best_match(
        self, pool: Dict[int, List[BufferInfo]], requested_size: int
    ) -> Optional[BufferInfo]:
        """
        Encuentra el mejor buffer disponible, permitiendo reutilizaci√≥n
        de buffers ligeramente m√°s grandes.
        """
        # Buscar tama√±o exacto primero
        if requested_size in pool and pool[requested_size]:
            return pool[requested_size].pop()

        # Buscar buffer m√°s grande (hasta 50% overhead permitido)
        max_acceptable = int(requested_size * 1.5)

        for size in sorted(pool.keys()):
            if size >= requested_size and size <= max_acceptable:
                if pool[size]:
                    return pool[size].pop()

        return None

    def get_buffer(
        self,
        size: int,
        read_only: bool = True,
        data: Optional[np.ndarray] = None,
        pin: bool = False,
    ) -> cl.Buffer:
        """
        Obtiene un buffer del pool o crea uno nuevo.

        Args:
            size: Tama√±o en bytes
            read_only: Si es buffer de solo lectura
            data: Datos opcionales para copiar
            pin: Si el buffer debe ser pinned (no evictable)

        Returns:
            Buffer de OpenCL
        """
        with self._lock:
            pool = self._read_pool if read_only else self._write_pool
            mf = cl.mem_flags

            # Intentar encontrar buffer existente
            buffer_info = self._find_best_match(pool, size)

            if buffer_info:
                self.stats.pool_hits += 1
                buffer_info.touch()

                # Copiar datos si se proporcionaron
                if data is not None:
                    cl.enqueue_copy(self.queue, buffer_info.buffer, data)

                if pin:
                    self._pinned_buffers.add(id(buffer_info.buffer))
                    buffer_info.is_pinned = True

                return buffer_info.buffer

            # Crear nuevo buffer
            self.stats.pool_misses += 1

            # Verificar si necesitamos evictar
            if self._current_pool_size + size > self.max_pool_memory * self.eviction_threshold:
                self._evict_cold_buffers(size)

            # Crear buffer
            if read_only:
                if data is not None:
                    buf = cl.Buffer(self.context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=data)
                else:
                    buf = cl.Buffer(self.context, mf.READ_ONLY, size)
            else:
                buf = cl.Buffer(self.context, mf.READ_WRITE, size)

            # Actualizar estad√≠sticas
            self._current_pool_size += size
            self.stats.total_allocated += size
            self.stats.current_usage = self._current_pool_size
            self.stats.peak_usage = max(self.stats.peak_usage, self._current_pool_size)

            if pin:
                self._pinned_buffers.add(id(buf))

            return buf

    def return_buffer(self, buf: cl.Buffer, read_only: bool = True):
        """Devuelve un buffer al pool para reutilizaci√≥n."""
        with self._lock:
            size = buf.size
            pool = self._read_pool if read_only else self._write_pool

            # No devolver si est√° pinned
            if id(buf) in self._pinned_buffers:
                return

            # Verificar l√≠mite de buffers por tama√±o
            if len(pool[size]) >= self.max_buffers_per_size:
                # Liberar el buffer m√°s viejo
                if pool[size]:
                    old_info = pool[size].pop(0)
                    old_info.buffer.release()
                    self._current_pool_size -= old_info.size
                    self.stats.total_freed += old_info.size

            # Agregar al pool
            info = BufferInfo(
                buffer=buf, size=size, tier=BufferTier.WARM, last_access=time.time(), access_count=1
            )
            pool[size].append(info)

    def _evict_cold_buffers(self, needed_size: int):
        """Evicta buffers COLD hasta liberar el espacio necesario."""
        freed = 0

        # Colectar todos los buffers con su info
        all_buffers = []
        for size, buffers in self._read_pool.items():
            for info in buffers:
                if not info.is_pinned:
                    all_buffers.append(("read", size, info))

        for size, buffers in self._write_pool.items():
            for info in buffers:
                if not info.is_pinned:
                    all_buffers.append(("write", size, info))

        # Ordenar por tier y √∫ltimo acceso (COLD primero, m√°s viejo primero)
        tier_priority = {BufferTier.COLD: 0, BufferTier.WARM: 1, BufferTier.HOT: 2}
        all_buffers.sort(key=lambda x: (tier_priority.get(x[2].tier, 1), x[2].last_access))

        # Evictar hasta tener suficiente espacio
        for pool_type, size, info in all_buffers:
            if freed >= needed_size:
                break

            pool = self._read_pool if pool_type == "read" else self._write_pool
            if info in pool[size]:
                pool[size].remove(info)
                info.buffer.release()
                freed += info.size
                self._current_pool_size -= info.size
                self.stats.evictions += 1
                self.stats.total_freed += info.size

        logger.debug(f"Evicted {freed / 1024**2:.1f} MB from pool")

    def pin_buffer(self, buf: cl.Buffer):
        """Marca un buffer como pinned (no evictable)."""
        with self._lock:
            self._pinned_buffers.add(id(buf))

    def unpin_buffer(self, buf: cl.Buffer):
        """Desmarca un buffer como pinned."""
        with self._lock:
            self._pinned_buffers.discard(id(buf))

    def clear(self):
        """Libera todos los buffers del pool."""
        with self._lock:
            for pool in [self._read_pool, self._write_pool]:
                for size, buffers in pool.items():
                    for info in buffers:
                        try:
                            info.buffer.release()
                        except:
                            pass
                pool.clear()

            self._current_pool_size = 0
            self._pinned_buffers.clear()

    def get_stats(self) -> MemoryStats:
        """Retorna estad√≠sticas del pool."""
        self.stats.current_usage = self._current_pool_size
        return self.stats


class TilingManager:
    """
    Gestiona el tiling de matrices grandes para reducir uso de memoria.

    Estrategias:
    - Matrices < 1024x1024: Sin tiling
    - Matrices 1024-4096: Tiles de 512x512
    - Matrices > 4096: Tiles de 1024x1024 o recursivo
    """

    # Umbrales de tama√±o
    NO_TILE_THRESHOLD = 1024 * 1024 * 4  # 4 MB (1024x1024 float32)
    MEDIUM_TILE_SIZE = 512
    LARGE_TILE_SIZE = 1024

    def __init__(
        self, buffer_pool: AdvancedBufferPool, queue: cl.CommandQueue, max_tiles_in_memory: int = 4
    ):
        self.buffer_pool = buffer_pool
        self.queue = queue
        self.max_tiles_in_memory = max_tiles_in_memory

        # Cache de tiles cargados
        self._loaded_tiles: OrderedDict[str, TileDescriptor] = OrderedDict()

    def select_strategy(
        self, matrix_shape: Tuple[int, int], dtype: Any = np.float32
    ) -> Tuple[TilingStrategy, int]:
        """
        Selecciona la estrategia de tiling √≥ptima.

        Returns:
            (strategy, tile_size)
        """
        rows, cols = matrix_shape
        element_size = np.dtype(dtype).itemsize
        total_size = rows * cols * element_size

        if total_size <= self.NO_TILE_THRESHOLD:
            return TilingStrategy.NONE, 0

        # Para matrices grandes, usar tiles
        if max(rows, cols) <= 4096:
            return TilingStrategy.SQUARE, self.MEDIUM_TILE_SIZE
        else:
            return TilingStrategy.SQUARE, self.LARGE_TILE_SIZE

    def create_tiles(self, matrix: np.ndarray, tile_size: int) -> List[TileDescriptor]:
        """
        Crea descriptores de tiles para una matriz.

        Args:
            matrix: Matriz a dividir
            tile_size: Tama√±o de cada tile

        Returns:
            Lista de TileDescriptor
        """
        rows, cols = matrix.shape
        dtype_size = matrix.dtype.itemsize
        tiles = []

        for row_start in range(0, rows, tile_size):
            row_end = min(row_start + tile_size, rows)

            for col_start in range(0, cols, tile_size):
                col_end = min(col_start + tile_size, cols)

                tile_rows = row_end - row_start
                tile_cols = col_end - col_start
                size_bytes = tile_rows * tile_cols * dtype_size

                tiles.append(
                    TileDescriptor(
                        row_start=row_start,
                        row_end=row_end,
                        col_start=col_start,
                        col_end=col_end,
                        size_bytes=size_bytes,
                    )
                )

        self.buffer_pool.stats.tiles_created += len(tiles)
        return tiles

    def load_tile(
        self, matrix: np.ndarray, tile: TileDescriptor, read_only: bool = True
    ) -> cl.Buffer:
        """
        Carga un tile espec√≠fico en memoria GPU.

        Args:
            matrix: Matriz fuente
            tile: Descriptor del tile
            read_only: Si es buffer de lectura

        Returns:
            Buffer de OpenCL con el tile
        """
        # Extraer datos del tile
        tile_data = matrix[tile.row_start : tile.row_end, tile.col_start : tile.col_end].copy()

        # Asegurar que es C-contiguous
        if not tile_data.flags["C_CONTIGUOUS"]:
            tile_data = np.ascontiguousarray(tile_data)

        # Obtener buffer del pool
        buf = self.buffer_pool.get_buffer(size=tile.size_bytes, read_only=read_only, data=tile_data)

        tile.buffer = buf
        tile.is_loaded = True

        # Gestionar cache LRU
        tile_key = f"{id(matrix)}_{tile.row_start}_{tile.col_start}"

        if len(self._loaded_tiles) >= self.max_tiles_in_memory:
            # Evictar el tile m√°s viejo
            oldest_key, oldest_tile = self._loaded_tiles.popitem(last=False)
            if oldest_tile.buffer:
                self.buffer_pool.return_buffer(oldest_tile.buffer, read_only=True)
                oldest_tile.is_loaded = False

        self._loaded_tiles[tile_key] = tile

        return buf

    def unload_tile(self, tile: TileDescriptor, read_only: bool = True):
        """Descarga un tile de memoria GPU."""
        if tile.buffer and tile.is_loaded:
            self.buffer_pool.return_buffer(tile.buffer, read_only=read_only)
            tile.buffer = None
            tile.is_loaded = False

    def clear_cache(self):
        """Limpia el cache de tiles."""
        for tile in self._loaded_tiles.values():
            self.unload_tile(tile)
        self._loaded_tiles.clear()


class PrefetchManager:
    """
    Gestiona prefetching as√≠ncrono de datos para ocultar latencia.

    Caracter√≠sticas:
    - Double buffering para transferencias solapadas
    - Predicci√≥n de acceso basada en patrones
    - Cola de prefetch con prioridad
    """

    def __init__(
        self, buffer_pool: AdvancedBufferPool, queue: cl.CommandQueue, prefetch_queue_size: int = 3
    ):
        self.buffer_pool = buffer_pool
        self.queue = queue
        self.prefetch_queue_size = prefetch_queue_size

        # Cola de prefetch
        self._prefetch_queue: List[Tuple[np.ndarray, bool]] = []
        self._prefetched_buffers: Dict[int, cl.Buffer] = {}

        # Estad√≠sticas
        self._prefetch_hits = 0
        self._prefetch_misses = 0

    def prefetch(self, data: np.ndarray, read_only: bool = True) -> Optional[cl.Buffer]:
        """
        Inicia prefetch as√≠ncrono de datos.

        Args:
            data: Datos a prefetchear
            read_only: Si el buffer es de lectura

        Returns:
            Buffer si el prefetch fue exitoso, None si la cola est√° llena
        """
        data_id = id(data)

        # Ya prefetcheado?
        if data_id in self._prefetched_buffers:
            return self._prefetched_buffers[data_id]

        # Cola llena?
        if len(self._prefetch_queue) >= self.prefetch_queue_size:
            return None

        # Iniciar transferencia as√≠ncrona
        buf = self.buffer_pool.get_buffer(size=data.nbytes, read_only=read_only, data=data)

        self._prefetched_buffers[data_id] = buf
        self.buffer_pool.stats.prefetch_hits += 1

        return buf

    def get_prefetched(self, data: np.ndarray) -> Optional[cl.Buffer]:
        """
        Obtiene un buffer prefetcheado.

        Args:
            data: Datos para los que se busca el prefetch

        Returns:
            Buffer si existe, None si no fue prefetcheado
        """
        data_id = id(data)

        if data_id in self._prefetched_buffers:
            self._prefetch_hits += 1
            buf = self._prefetched_buffers.pop(data_id)
            return buf

        self._prefetch_misses += 1
        self.buffer_pool.stats.prefetch_misses += 1
        return None

    def clear(self):
        """Limpia buffers prefetcheados."""
        for buf in self._prefetched_buffers.values():
            self.buffer_pool.return_buffer(buf, read_only=True)
        self._prefetched_buffers.clear()
        self._prefetch_queue.clear()


class AdvancedMemoryManager:
    """
    Sistema integrado de gesti√≥n de memoria avanzada.

    Combina:
    - BufferPool con tiers y evicci√≥n inteligente
    - TilingManager para matrices grandes
    - PrefetchManager para ocultar latencia
    - Compresi√≥n opcional de sparse matrices
    """

    def __init__(
        self,
        context: cl.Context,
        queue: cl.CommandQueue,
        max_gpu_memory: int = 4 * 1024 * 1024 * 1024,  # 4 GB default
        enable_prefetch: bool = True,
        enable_tiling: bool = True,
        enable_compression: bool = True,
    ):
        self.context = context
        self.queue = queue
        self.max_gpu_memory = max_gpu_memory

        # Componentes
        self.buffer_pool = AdvancedBufferPool(
            context=context, queue=queue, max_pool_memory=max_gpu_memory // 2  # 50% para pool
        )

        self.tiling_manager = (
            TilingManager(buffer_pool=self.buffer_pool, queue=queue) if enable_tiling else None
        )

        self.prefetch_manager = (
            PrefetchManager(buffer_pool=self.buffer_pool, queue=queue) if enable_prefetch else None
        )

        self.enable_compression = enable_compression

        # Tracking de memoria
        self._allocated_buffers: Dict[int, Tuple[cl.Buffer, int]] = {}

        logger.info("AdvancedMemoryManager initialized")
        logger.info(f"  Max GPU Memory: {max_gpu_memory / 1024**3:.1f} GB")
        logger.info(f"  Prefetch: {'enabled' if enable_prefetch else 'disabled'}")
        logger.info(f"  Tiling: {'enabled' if enable_tiling else 'disabled'}")

    def allocate(
        self,
        data: np.ndarray,
        read_only: bool = True,
        use_tiling: bool = False,
        prefetch_next: Optional[np.ndarray] = None,
    ) -> cl.Buffer:
        """
        Aloca buffer de forma inteligente.

        Args:
            data: Datos a transferir
            read_only: Si es buffer de lectura
            use_tiling: Forzar uso de tiling
            prefetch_next: Datos a prefetchear para siguiente operaci√≥n

        Returns:
            Buffer de OpenCL
        """
        # Verificar si ya fue prefetcheado
        if self.prefetch_manager:
            prefetched = self.prefetch_manager.get_prefetched(data)
            if prefetched:
                return prefetched

        # Prefetch siguiente dato si se proporciona
        if self.prefetch_manager and prefetch_next is not None:
            self.prefetch_manager.prefetch(prefetch_next, read_only=True)

        # Verificar si necesita tiling
        if self.tiling_manager and use_tiling:
            strategy, tile_size = self.tiling_manager.select_strategy(data.shape)

            if strategy != TilingStrategy.NONE:
                # Por ahora, cargar como un solo buffer
                # El tiling se usa para operaciones que lo requieran expl√≠citamente
                pass

        # Compresi√≥n para sparse matrices
        if self.enable_compression and self._is_sparse(data):
            return self._allocate_compressed(data, read_only)

        # Alocaci√≥n normal via pool
        buf = self.buffer_pool.get_buffer(size=data.nbytes, read_only=read_only, data=data)

        self._allocated_buffers[id(buf)] = (buf, data.nbytes)

        return buf

    def _is_sparse(self, data: np.ndarray, threshold: float = 0.7) -> bool:
        """Detecta si una matriz es sparse (>70% ceros)."""
        if data.size == 0:
            return False
        sparsity = 1.0 - (np.count_nonzero(data) / data.size)
        return sparsity > threshold

    def _allocate_compressed(self, data: np.ndarray, read_only: bool = True) -> cl.Buffer:
        """
        Aloca matriz sparse en formato comprimido.
        Por ahora usa COO simple, podr√≠a expandirse a CSR/CSC.
        """
        # Encontrar elementos no-cero
        nonzero_mask = data != 0
        values = data[nonzero_mask].astype(np.float32)
        indices = np.argwhere(nonzero_mask).astype(np.int32)

        # Calcular ahorro de memoria
        original_size = data.nbytes
        compressed_size = values.nbytes + indices.nbytes

        if compressed_size < original_size:
            self.buffer_pool.stats.compression_savings += original_size - compressed_size
            # Para simplificar, a√∫n transferimos la matriz completa
            # Una implementaci√≥n completa usar√≠a kernels sparse

        # Alocaci√≥n normal por ahora
        return self.buffer_pool.get_buffer(size=data.nbytes, read_only=read_only, data=data)

    def free(self, buf: cl.Buffer, read_only: bool = True):
        """Libera un buffer, devolvi√©ndolo al pool."""
        if id(buf) in self._allocated_buffers:
            del self._allocated_buffers[id(buf)]
        self.buffer_pool.return_buffer(buf, read_only=read_only)

    @contextmanager
    def managed_buffer(self, data: np.ndarray, read_only: bool = True):
        """
        Context manager para manejo autom√°tico de buffers.

        Usage:
            with memory_manager.managed_buffer(data) as buf:
                # usar buf
            # buffer autom√°ticamente devuelto al pool
        """
        buf = self.allocate(data, read_only=read_only)
        try:
            yield buf
        finally:
            self.free(buf, read_only=read_only)

    def get_tiled_buffers(
        self, matrix: np.ndarray, tile_size: Optional[int] = None
    ) -> List[Tuple[TileDescriptor, cl.Buffer]]:
        """
        Obtiene buffers para tiles de una matriz grande.

        Args:
            matrix: Matriz a dividir
            tile_size: Tama√±o de tile (auto si None)

        Returns:
            Lista de (descriptor, buffer) para cada tile
        """
        if not self.tiling_manager:
            raise RuntimeError("Tiling not enabled")

        # Seleccionar estrategia si no se especifica tile_size
        if tile_size is None:
            _, tile_size = self.tiling_manager.select_strategy(matrix.shape)
            if tile_size == 0:
                tile_size = 512  # Default

        tiles = self.tiling_manager.create_tiles(matrix, tile_size)
        result = []

        for tile in tiles:
            buf = self.tiling_manager.load_tile(matrix, tile)
            result.append((tile, buf))

        return result

    def get_stats(self) -> MemoryStats:
        """Retorna estad√≠sticas de memoria."""
        return self.buffer_pool.get_stats()

    def clear(self):
        """Limpia todos los recursos."""
        if self.prefetch_manager:
            self.prefetch_manager.clear()
        if self.tiling_manager:
            self.tiling_manager.clear_cache()
        self.buffer_pool.clear()
        self._allocated_buffers.clear()


def run_memory_benchmark():
    """Benchmark del sistema de memoria avanzado."""
    import pyopencl as cl

    print("=" * 70)
    print("üß† ADVANCED MEMORY MANAGER BENCHMARK")
    print("=" * 70)

    # Setup OpenCL
    platform = cl.get_platforms()[0]
    device = platform.get_devices()[0]
    context = cl.Context([device])
    queue = cl.CommandQueue(context, properties=cl.command_queue_properties.PROFILING_ENABLE)

    print(f"\nDevice: {device.name}")
    print(f"Memory: {device.global_mem_size / 1024**3:.1f} GB")

    # Crear manager
    manager = AdvancedMemoryManager(
        context=context,
        queue=queue,
        max_gpu_memory=device.global_mem_size,
        enable_prefetch=True,
        enable_tiling=True,
    )

    # Benchmark
    test_sizes = [256, 512, 1024, 2048]
    results = []

    for size in test_sizes:
        print(f"\nüìä Testing {size}x{size} matrices...")

        # Sin memory manager (baseline)
        A = np.random.randn(size, size).astype(np.float32)
        B = np.random.randn(size, size).astype(np.float32)

        # Medir memoria antes
        stats_before = manager.get_stats()
        mem_before = stats_before.current_usage

        # Con memory manager
        iterations = 5
        start = time.time()

        for i in range(iterations):
            # Simular operaci√≥n con prefetch
            next_data = B if i < iterations - 1 else None

            with manager.managed_buffer(A) as buf_a:
                with manager.managed_buffer(B) as buf_b:
                    # Simular uso
                    queue.finish()

        elapsed = time.time() - start

        # Estad√≠sticas
        stats_after = manager.get_stats()

        results.append(
            {
                "size": size,
                "time_per_iter": elapsed / iterations * 1000,
                "hit_rate": stats_after.hit_rate,
                "peak_memory_mb": stats_after.peak_usage / 1024**2,
            }
        )

        print(f"   Time per iteration: {elapsed / iterations * 1000:.2f} ms")
        print(f"   Pool hit rate: {stats_after.hit_rate:.1%}")
        print(f"   Peak memory: {stats_after.peak_usage / 1024**2:.1f} MB")

    # Resumen
    print("\n" + "=" * 70)
    print("üìà SUMMARY")
    print("=" * 70)

    stats = manager.get_stats()
    print(stats.summary())

    # Calcular reducci√≥n de memoria
    theoretical_mem = sum(2 * s**2 * 4 * 5 for s in test_sizes)  # A+B, 5 iters cada uno
    actual_peak = stats.peak_usage

    reduction = (1 - actual_peak / (theoretical_mem / len(test_sizes))) * 100
    print(f"\nüéØ Memory reduction estimate: {reduction:.1f}%")
    print(f"   Target: 50%")
    print(f"   Status: {'‚úÖ ACHIEVED' if reduction >= 50 else '‚ùå NOT YET'}")

    manager.clear()
    return results


if __name__ == "__main__":
    run_memory_benchmark()
