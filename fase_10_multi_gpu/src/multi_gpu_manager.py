#!/usr/bin/env python3
"""
üöÄ FASE 10: MULTI-GPU MATRIX MULTIPLICATION FRAMEWORK
======================================================

Framework extensible para computaci√≥n distribuida en m√∫ltiples GPUs Radeon RX 580.
Dise√±ado para escalar de 1 a N GPUs con distribuci√≥n inteligente de carga de trabajo.

Caracter√≠sticas:
- Arquitectura modular y extensible
- Distribuci√≥n autom√°tica de matrices
- Sincronizaci√≥n eficiente entre GPUs
- Manejo robusto de errores
- Logging completo para debugging
- Compatible con t√©cnicas h√≠bridas existentes

Autor: AI Assistant
Fecha: 2026-01-25
"""

import os
import sys
import time
import logging
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

try:
    import pyopencl as cl
    import pyopencl.array as cl_array
    PYOPENCL_AVAILABLE = True
except ImportError:
    PYOPENCL_AVAILABLE = False
    print("‚ùå PyOpenCL no disponible. Instalar con: pip install pyopencl")
    sys.exit(1)

@dataclass
class GPUDevice:
    """Informaci√≥n de un dispositivo GPU."""
    device: cl.Device
    platform: cl.Platform
    context: cl.Context
    queue: cl.CommandQueue
    name: str
    memory_gb: float
    compute_units: int
    max_work_group_size: int
    device_id: int

@dataclass
class WorkloadDistribution:
    """Distribuci√≥n de carga de trabajo entre GPUs."""
    gpu_id: int
    matrix_slice: Tuple[int, int, int, int]  # (start_row, end_row, start_col, end_col)
    data_size: int
    estimated_time: float

class MultiGPUManager:
    """
    Administrador de m√∫ltiples GPUs para operaciones matriciales distribuidas.

    Arquitectura:
    - Descubrimiento autom√°tico de GPUs AMD
    - Distribuci√≥n inteligente de carga de trabajo
    - Sincronizaci√≥n de resultados
    - Manejo de fallos y recuperaci√≥n
    """

    def __init__(self, log_level: str = "INFO"):
        """
        Inicializa el administrador multi-GPU.

        Args:
            log_level: Nivel de logging (DEBUG, INFO, WARNING, ERROR)
        """
        self.logger = self._setup_logging(log_level)
        self.devices: List[GPUDevice] = []
        self.kernels_cache: Dict[str, cl.Kernel] = {}
        self.workload_lock = threading.Lock()

        self.logger.info("üöÄ Inicializando Multi-GPU Manager...")
        self._discover_devices()
        self._validate_configuration()

    def _setup_logging(self, level: str) -> logging.Logger:
        """Configura el sistema de logging."""
        logger = logging.getLogger("MultiGPUManager")
        logger.setLevel(getattr(logging, level.upper()))

        # Handler para consola
        console_handler = logging.StreamHandler()
        console_handler.setLevel(getattr(logging, level.upper()))

        # Formato
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(formatter)

        # Evitar duplicados
        if not logger.handlers:
            logger.addHandler(console_handler)

        return logger

    def _discover_devices(self):
        """Descubre y configura todos los dispositivos GPU disponibles."""
        self.logger.info("üîç Descubriendo dispositivos GPU...")

        try:
            platforms = cl.get_platforms()
            device_count = 0

            for platform in platforms:
                # Priorizar AMD platforms
                if 'AMD' in platform.name.upper() or 'ATI' in platform.name.upper():
                    self.logger.info(f"üéØ Plataforma AMD encontrada: {platform.name}")

                    devices = platform.get_devices(device_type=cl.device_type.GPU)

                    for device in devices:
                        gpu_device = self._create_gpu_device(device, platform, device_count)
                        self.devices.append(gpu_device)
                        device_count += 1

                        self.logger.info(f"‚úÖ GPU {device_count}: {gpu_device.name}")
                        self.logger.info(f"   Memoria: {gpu_device.memory_gb:.1f} GB")
                        self.logger.info(f"   Compute Units: {gpu_device.compute_units}")
                        self.logger.info(f"   Max Work Group: {gpu_device.max_work_group_size}")

            if not self.devices:
                self.logger.warning("‚ö†Ô∏è  No se encontraron GPUs AMD. Usando GPUs gen√©ricas...")
                # Fallback a cualquier GPU disponible
                for platform in platforms:
                    devices = platform.get_devices(device_type=cl.device_type.GPU)
                    for device in devices:
                        gpu_device = self._create_gpu_device(device, platform, device_count)
                        self.devices.append(gpu_device)
                        device_count += 1

        except Exception as e:
            self.logger.error(f"‚ùå Error descubriendo dispositivos: {e}")
            raise

    def _create_gpu_device(self, device: cl.Device, platform: cl.Platform, device_id: int) -> GPUDevice:
        """Crea un objeto GPUDevice configurado."""
        try:
            # Crear contexto y queue
            context = cl.Context([device])
            queue = cl.CommandQueue(context)

            # Informaci√≥n del dispositivo
            name = device.name
            memory_gb = device.global_mem_size / (1024**3)
            compute_units = device.max_compute_units
            max_work_group_size = device.max_work_group_size

            return GPUDevice(
                device=device,
                platform=platform,
                context=context,
                queue=queue,
                name=name,
                memory_gb=memory_gb,
                compute_units=compute_units,
                max_work_group_size=max_work_group_size,
                device_id=device_id
            )

        except Exception as e:
            self.logger.error(f"‚ùå Error creando GPU device {device_id}: {e}")
            raise

    def _validate_configuration(self):
        """Valida la configuraci√≥n multi-GPU."""
        if not self.devices:
            raise RuntimeError("‚ùå No hay GPUs disponibles")

        self.logger.info(f"‚úÖ Configuraci√≥n validada: {len(self.devices)} GPUs disponibles")

        # Verificar compatibilidad entre dispositivos
        if len(self.devices) > 1:
            self._check_device_compatibility()

    def _check_device_compatibility(self):
        """Verifica compatibilidad entre m√∫ltiples dispositivos."""
        # Para simplificar, asumimos que GPUs AMD son compatibles
        # En implementaci√≥n real, verificar versiones OpenCL, etc.
        self.logger.info("üîç Verificando compatibilidad entre dispositivos...")

        base_device = self.devices[0]
        for device in self.devices[1:]:
            if 'AMD' not in device.name.upper() and 'ATI' not in device.name.upper():
                self.logger.warning(f"‚ö†Ô∏è  Dispositivo {device.name} no es AMD - posible incompatibilidad")

        self.logger.info("‚úÖ Compatibilidad verificada")

    def get_optimal_workload_distribution(self, M: int, N: int, K: int) -> List[WorkloadDistribution]:
        """
        Calcula la distribuci√≥n √≥ptima de carga de trabajo.

        Estrategias de distribuci√≥n:
        1. Row-wise: Dividir filas de la matriz resultado
        2. Block-wise: Dividir en bloques cuadrados
        3. Load-balanced: Considerar capacidad de cada GPU

        Args:
            M, N, K: Dimensiones de las matrices (M x K) * (K x N) = (M x N)

        Returns:
            Lista de distribuciones de carga de trabajo
        """
        self.logger.info(f"üìä Calculando distribuci√≥n √≥ptima para {M}x{N}x{K}")

        if not self.devices:
            raise RuntimeError("No hay dispositivos disponibles")

        num_gpus = len(self.devices)
        distributions = []

        if num_gpus == 1:
            # Caso single GPU
            dist = WorkloadDistribution(
                gpu_id=0,
                matrix_slice=(0, M, 0, N),
                data_size=M * N * K,
                estimated_time=self._estimate_computation_time(M, N, K, self.devices[0])
            )
            distributions.append(dist)
        else:
            # Distribuci√≥n multi-GPU: dividir por filas
            rows_per_gpu = M // num_gpus
            remainder = M % num_gpus

            current_row = 0
            for i, device in enumerate(self.devices):
                start_row = current_row
                end_row = current_row + rows_per_gpu + (1 if i < remainder else 0)

                dist = WorkloadDistribution(
                    gpu_id=i,
                    matrix_slice=(start_row, end_row, 0, N),
                    data_size=(end_row - start_row) * N * K,
                    estimated_time=self._estimate_computation_time(
                        end_row - start_row, N, K, device
                    )
                )
                distributions.append(dist)
                current_row = end_row

        self.logger.info(f"üìã Distribuci√≥n calculada para {num_gpus} GPUs:")
        for dist in distributions:
            self.logger.info(f"  GPU {dist.gpu_id}: filas {dist.matrix_slice[0]}-{dist.matrix_slice[1]} "
                           f"(tama√±o: {dist.data_size:,} elementos)")

        return distributions

    def _estimate_computation_time(self, M: int, N: int, K: int, device: GPUDevice) -> float:
        """
        Estima el tiempo de computaci√≥n para una GPU espec√≠fica.

        Factores considerados:
        - FLOPs totales: 2 * M * N * K
        - Capacidad de la GPU (compute units, frecuencia)
        - Memoria disponible
        - Eficiencia del kernel

        Returns:
            Tiempo estimado en segundos
        """
        # Estimaci√≥n simplificada basada en FLOPs
        total_flops = 2.0 * M * N * K  # Multiplicaciones + sumas

        # Asumir rendimiento base de RX 580 ~ 6 TFLOPS
        base_performance = 6e12  # FLOPS

        # Factor de eficiencia (kernel optimizado)
        efficiency_factor = 0.7

        # Ajuste por capacidad de la GPU
        capacity_factor = device.compute_units / 36.0  # RX 580 tiene 36 CUs

        estimated_flops = base_performance * efficiency_factor * capacity_factor

        return total_flops / estimated_flops

    def distribute_matrix_data(self, A: np.ndarray, B: np.ndarray,
                             distributions: List[WorkloadDistribution]) -> Dict[int, Dict[str, Any]]:
        """
        Distribuye los datos de matrices a cada GPU.

        Args:
            A, B: Matrices de entrada
            distributions: Distribuci√≥n de carga de trabajo

        Returns:
            Diccionario con datos distribuidos por GPU
        """
        self.logger.info("üì§ Distribuyendo datos de matrices...")

        distributed_data = {}

        for dist in distributions:
            gpu_id = dist.gpu_id
            start_row, end_row, start_col, end_col = dist.matrix_slice

            # Para distribuci√≥n row-wise, cada GPU necesita:
            # - Su porci√≥n de filas de A
            # - Toda la matriz B
            # - Espacio para resultado C

            A_slice = A[start_row:end_row, :]  # Filas correspondientes
            B_full = B  # Toda B
            C_slice = np.zeros((end_row - start_row, B.shape[1]), dtype=np.float32)

            # Transferir a GPU
            gpu_data = self._transfer_to_gpu(gpu_id, A_slice, B_full, C_slice)
            distributed_data[gpu_id] = gpu_data

        self.logger.info("‚úÖ Datos distribuidos exitosamente")
        return distributed_data

    def _transfer_to_gpu(self, gpu_id: int, A: np.ndarray, B: np.ndarray, C: np.ndarray) -> Dict[str, Any]:
        """Transfiere matrices a la memoria de una GPU espec√≠fica."""
        device = self.devices[gpu_id]

        try:
            # Crear buffers OpenCL
            mf = cl.mem_flags
            A_buf = cl.Buffer(device.context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=A)
            B_buf = cl.Buffer(device.context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=B)
            C_buf = cl.Buffer(device.context, mf.WRITE_ONLY, C.nbytes)

            return {
                'A_buf': A_buf,
                'B_buf': B_buf,
                'C_buf': C_buf,
                'A_shape': A.shape,
                'B_shape': B.shape,
                'C_shape': C.shape,
                'device': device
            }

        except Exception as e:
            self.logger.error(f"‚ùå Error transfiriendo datos a GPU {gpu_id}: {e}")
            raise

    def execute_distributed_computation(self, distributed_data: Dict[int, Dict[str, Any]],
                                      kernel_name: str = "gemm_basic") -> Dict[int, np.ndarray]:
        """
        Ejecuta la computaci√≥n distribuida en todas las GPUs.

        Args:
            distributed_data: Datos distribuidos por GPU
            kernel_name: Nombre del kernel OpenCL a usar

        Returns:
            Resultados parciales por GPU
        """
        self.logger.info("üöÄ Ejecutando computaci√≥n distribuida...")

        results = {}

        # Ejecutar en paralelo usando ThreadPoolExecutor
        with ThreadPoolExecutor(max_workers=len(distributed_data)) as executor:
            futures = {}

            for gpu_id, gpu_data in distributed_data.items():
                future = executor.submit(self._execute_single_gpu, gpu_id, gpu_data, kernel_name)
                futures[future] = gpu_id

            # Recolectar resultados
            for future in as_completed(futures):
                gpu_id = futures[future]
                try:
                    result = future.result()
                    results[gpu_id] = result
                    self.logger.info(f"‚úÖ GPU {gpu_id} complet√≥ su tarea")
                except Exception as e:
                    self.logger.error(f"‚ùå Error en GPU {gpu_id}: {e}")
                    raise

        self.logger.info("‚úÖ Computaci√≥n distribuida completada")
        return results

    def _execute_single_gpu(self, gpu_id: int, gpu_data: Dict[str, Any], kernel_name: str) -> np.ndarray:
        """Ejecuta computaci√≥n en una GPU espec√≠fica."""
        device = gpu_data['device']
        A_buf = gpu_data['A_buf']
        B_buf = gpu_data['B_buf']
        C_buf = gpu_data['C_buf']
        A_shape = gpu_data['A_shape']
        B_shape = gpu_data['B_shape']
        C_shape = gpu_data['C_shape']

        try:
            # Cargar kernel (implementaci√≥n b√°sica por ahora)
            kernel = self._load_kernel(device, kernel_name)

            # Configurar kernel arguments
            kernel.set_args(A_buf, B_buf, C_buf,
                          np.int32(A_shape[0]), np.int32(A_shape[1]),
                          np.int32(B_shape[1]))

            # Ejecutar kernel
            global_size = (C_shape[0], C_shape[1])
            local_size = None  # Dejar que OpenCL decida

            cl.enqueue_nd_range_kernel(device.queue, kernel, global_size, local_size)

            # Leer resultado
            result = np.zeros(C_shape, dtype=np.float32)
            cl.enqueue_copy(device.queue, result, C_buf)

            device.queue.finish()

            return result

        except Exception as e:
            self.logger.error(f"‚ùå Error ejecutando en GPU {gpu_id}: {e}")
            raise

    def _load_kernel(self, device: GPUDevice, kernel_name: str) -> cl.Kernel:
        """Carga un kernel OpenCL."""
        # Por ahora, kernel b√°sico embebido
        kernel_source = """
        __kernel void gemm_basic(__global const float* A,
                                __global const float* B,
                                __global float* C,
                                const int M, const int K, const int N) {
            int row = get_global_id(0);
            int col = get_global_id(1);

            if (row < M && col < N) {
                float sum = 0.0f;
                for (int i = 0; i < K; i++) {
                    sum += A[row * K + i] * B[i * N + col];
                }
                C[row * N + col] = sum;
            }
        }
        """

        try:
            program = cl.Program(device.context, kernel_source)
            program.build()
            kernel = cl.Kernel(program, kernel_name)
            return kernel
        except Exception as e:
            self.logger.error(f"‚ùå Error compilando kernel: {e}")
            raise

    def combine_results(self, partial_results: Dict[int, np.ndarray],
                       distributions: List[WorkloadDistribution]) -> np.ndarray:
        """
        Combina los resultados parciales de todas las GPUs.

        Args:
            partial_results: Resultados por GPU
            distributions: Distribuci√≥n original

        Returns:
            Matriz resultado completa
        """
        self.logger.info("üîó Combinando resultados parciales...")

        if len(partial_results) == 1:
            # Caso single GPU
            return list(partial_results.values())[0]

        # Reconstruir matriz completa
        first_dist = distributions[0]
        total_rows = sum(dist.matrix_slice[1] - dist.matrix_slice[0] for dist in distributions)
        total_cols = first_dist.matrix_slice[3] - first_dist.matrix_slice[2]

        combined_result = np.zeros((total_rows, total_cols), dtype=np.float32)

        for dist in distributions:
            gpu_id = dist.gpu_id
            start_row, end_row, start_col, end_col = dist.matrix_slice

            partial = partial_results[gpu_id]
            combined_result[start_row:end_row, start_col:end_col] = partial

        self.logger.info("‚úÖ Resultados combinados exitosamente")
        return combined_result

    def benchmark_multi_gpu_setup(self) -> Dict[str, Any]:
        """
        Benchmark del setup multi-GPU.

        Returns:
            M√©tricas de performance y configuraci√≥n
        """
        self.logger.info("üìä Ejecutando benchmark multi-GPU...")

        metrics = {
            'num_gpus': len(self.devices),
            'total_memory_gb': sum(d.memory_gb for d in self.devices),
            'total_compute_units': sum(d.compute_units for d in self.devices),
            'device_info': []
        }

        for device in self.devices:
            device_info = {
                'name': device.name,
                'memory_gb': device.memory_gb,
                'compute_units': device.compute_units,
                'max_work_group_size': device.max_work_group_size
            }
            metrics['device_info'].append(device_info)

        # Test de comunicaci√≥n (ping-pong si hay m√∫ltiples GPUs)
        if len(self.devices) > 1:
            metrics['communication_test'] = self._test_inter_gpu_communication()

        self.logger.info("‚úÖ Benchmark completado")
        return metrics

    def _test_inter_gpu_communication(self) -> Dict[str, Any]:
        """Test de comunicaci√≥n entre GPUs."""
        # Implementaci√≥n simplificada: medir latencia de transferencias
        self.logger.info("üîÑ Probando comunicaci√≥n inter-GPU...")

        # Crear datos de prueba
        test_size = 1024 * 1024  # 1M elementos
        test_data = np.random.rand(test_size).astype(np.float32)

        latencies = []
        for i in range(len(self.devices)):
            for j in range(len(self.devices)):
                if i != j:
                    # Transferir de GPU i a GPU j
                    start_time = time.time()

                    # Simular transferencia (en implementaci√≥n real, usar CL buffers)
                    # Por ahora, solo medir overhead
                    end_time = time.time()
                    latency = end_time - start_time
                    latencies.append(latency)

        avg_latency = np.mean(latencies) if latencies else 0.0

        return {
            'avg_latency_ms': avg_latency * 1000,
            'min_latency_ms': min(latencies) * 1000 if latencies else 0.0,
            'max_latency_ms': max(latencies) * 1000 if latencies else 0.0
        }

    def get_scaling_efficiency(self, single_gpu_time: float, multi_gpu_time: float) -> float:
        """
        Calcula la eficiencia de escalado.

        Eficiencia = (T_single / T_multi) / N_gpus

        Args:
            single_gpu_time: Tiempo con una GPU
            multi_gpu_time: Tiempo con m√∫ltiples GPUs

        Returns:
            Eficiencia de escalado (0-1, donde 1 es ideal)
        """
        if multi_gpu_time == 0 or single_gpu_time == 0:
            return 0.0

        num_gpus = len(self.devices)
        efficiency = (single_gpu_time / multi_gpu_time) / num_gpus

        return max(0.0, min(1.0, efficiency))  # Clamp to [0, 1]

    def cleanup(self):
        """Limpia recursos de todas las GPUs."""
        self.logger.info("üßπ Limpiando recursos multi-GPU...")

        for device in self.devices:
            try:
                device.queue.finish()
                # Liberar buffers si es necesario
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è  Error limpiando GPU {device.device_id}: {e}")

        self.logger.info("‚úÖ Limpieza completada")


# Funciones de utilidad para integraci√≥n con el framework existente

def create_multi_gpu_gemm(M: int, N: int, K: int, num_gpus_desired: Optional[int] = None) -> MultiGPUManager:
    """
    Crea un administrador multi-GPU optimizado para GEMM.

    Args:
        M, N, K: Dimensiones de matrices
        num_gpus_desired: N√∫mero deseado de GPUs (None = usar todas)

    Returns:
        MultiGPUManager configurado
    """
    manager = MultiGPUManager()

    if num_gpus_desired and num_gpus_desired < len(manager.devices):
        # Usar solo las primeras N GPUs
        manager.devices = manager.devices[:num_gpus_desired]
        manager.logger.info(f"üîß Usando {num_gpus_desired} de {len(manager.devices)} GPUs disponibles")

    return manager


def distributed_gemm(A: np.ndarray, B: np.ndarray, manager: MultiGPUManager) -> np.ndarray:
    """
    Realiza multiplicaci√≥n de matrices distribuida.

    Args:
        A, B: Matrices de entrada
        manager: MultiGPUManager configurado

    Returns:
        Matriz resultado
    """
    M, K = A.shape
    K2, N = B.shape

    if K != K2:
        raise ValueError("Dimensiones incompatibles para multiplicaci√≥n de matrices")

    # Calcular distribuci√≥n
    distributions = manager.get_optimal_workload_distribution(M, N, K)

    # Distribuir datos
    distributed_data = manager.distribute_matrix_data(A, B, distributions)

    # Ejecutar computaci√≥n
    partial_results = manager.execute_distributed_computation(distributed_data)

    # Combinar resultados
    result = manager.combine_results(partial_results, distributions)

    return result


if __name__ == "__main__":
    # Demo del framework multi-GPU
    print("üöÄ Demo: Multi-GPU Matrix Multiplication Framework")
    print("=" * 60)

    try:
        # Crear manager
        manager = MultiGPUManager(log_level="INFO")

        # Benchmark del setup
        metrics = manager.benchmark_multi_gpu_setup()
        print(f"üìä Setup: {metrics['num_gpus']} GPUs, {metrics['total_memory_gb']:.1f} GB total")

        # Test con matrices peque√±as
        M, N, K = 512, 512, 512
        A = np.random.rand(M, K).astype(np.float32)
        B = np.random.rand(K, N).astype(np.float32)

        print(f"üßÆ Test: {M}x{N}x{K} matrices")

        start_time = time.time()
        C = distributed_gemm(A, B, manager)
        end_time = time.time()

        print(".2f")
        print(f"‚úÖ Resultado: {C.shape}, error m√°ximo: {np.max(np.abs(C - A @ B)):.2e}")

        # Cleanup
        manager.cleanup()

    except Exception as e:
        print(f"‚ùå Error en demo: {e}")
        import traceback
        traceback.print_exc()