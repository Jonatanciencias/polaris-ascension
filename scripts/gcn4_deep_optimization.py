#!/usr/bin/env python3
"""
GCN 4.0 Deep Optimization - Phase 5 Redesign
Implementar optimizaciones profundas para alcanzar 950-1050 GFLOPS

Target: 950-1050 GFLOPS (+11-22% desde 855.6 GFLOPS)
Estrategia: Float8 operations, ISA analysis, wavefront optimization, advanced prefetching
"""

import sys
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple, Optional
import logging

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / 'src'))

from opencl.gemm_gcn4_refined import GCN4RefinedGEMMExecutor, GCN4RefinedConfig
import numpy as np

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    import pyopencl as cl
    PYOPENCL_AVAILABLE = True
except ImportError:
    PYOPENCL_AVAILABLE = False
    logger.warning("PyOpenCL not available")

class GCN4DeepOptimizationConfig:
    """Configuraci√≥n avanzada para optimizaciones profundas de GCN 4.0."""

    def __init__(self,
                 tile_size: int = 16,
                 workgroup_size: Tuple[int, int] = (16, 16),
                 lds_padding: int = 2,
                 use_float8: bool = True,
                 use_prefetching: bool = True,
                 wavefront_optimization: bool = True):
        self.tile_size = tile_size
        self.workgroup_size = workgroup_size
        self.lds_padding = lds_padding
        self.use_float8 = use_float8
        self.use_prefetching = use_prefetching
        self.wavefront_optimization = wavefront_optimization

    def get_compiler_options(self) -> str:
        """Opciones de compilador optimizadas para GCN 4.0."""
        options = [
            "-cl-mad-enable",
            "-cl-unsafe-math-optimizations",
            "-cl-fast-relaxed-math",
            "-cl-strict-aliasing",
            f"-DTILE_SIZE={self.tile_size}",
            f"-DWG_SIZE_X={self.workgroup_size[0]}",
            f"-DWG_SIZE_Y={self.workgroup_size[1]}",
            f"-DLDS_PADDING={self.lds_padding}"
        ]

        if self.use_float8:
            options.append("-DUSE_FLOAT8=1")
        if self.use_prefetching:
            options.append("-DUSE_PREFETCHING=1")
        if self.wavefront_optimization:
            options.append("-DWAVEFRONT_OPT=1")

        return " ".join(options)

class GCN4DeepOptimizedKernel:
    """Kernel altamente optimizado para GCN 4.0 con m√∫ltiples t√©cnicas avanzadas."""

    @staticmethod
    def create_kernel_source(config: GCN4DeepOptimizationConfig) -> str:
        """Crear el c√≥digo fuente del kernel optimizado."""
        kernel_code = f"""
/**
 * GCN 4.0 Deep Optimized GEMM Kernel - Ultimate Performance v3.0
 * Polaris 10 architecture exploitation for maximum performance
 *
 * Target: 950-1050 GFLOPS (11-22% improvement over 855.6 GFLOPS)
 * Hardware: AMD Radeon RX 590 (Polaris 10, GCN 4.0)
 *
 * Advanced Optimizations:
 * - Float8 operations for dual FMA units (16 FLOPS/cycle theoretical)
 * - Double-buffered prefetching with async operations
 * - Wavefront scheduling optimization (64 lanes √ó 36 CU)
 * - Advanced LDS banking (32 banks, conflict-free)
 * - Instruction-level parallelism maximization
 */

#ifndef TILE_SIZE
#define TILE_SIZE 16
#endif

#ifndef WG_SIZE_X
#define WG_SIZE_X 16
#endif

#ifndef WG_SIZE_Y
#define WG_SIZE_Y 16
#endif

#ifndef LDS_PADDING
#define LDS_PADDING 2
#endif

// GCN 4.0 architecture constants
#define GCN4_LDS_BANKS 32
#define GCN4_WAVEFRONT_SIZE 64
#define GCN4_CU_COUNT 36
#define GCN4_FMA_UNITS_PER_CU 2

/**
 * GCN 4.0 Deep Optimized GEMM Kernel
 * Combines multiple advanced techniques for maximum performance
 */
__kernel void gemm_gcn4_deep_optimized(
    const int M, const int N, const int K,
    const float alpha, const float beta,
    __global const float* A,
    __global const float* B,
    __global float* C)
{{
    const int local_x = get_local_id(0);
    const int local_y = get_local_id(1);
    const int global_x = get_global_id(0);
    const int global_y = get_global_id(1);

    // Early exit for out-of-bounds threads
    if (global_x >= N || global_y >= M) return;

    // GCN 4.0: SALU precalculation for all addresses
    const int wg_x = get_local_size(0);
    const int wg_y = get_local_size(1);
    const int group_x = get_group_id(0);
    const int group_y = get_group_id(1);

    // Initialize accumulator based on optimization level
#ifdef USE_FLOAT8
    // Float8 operations for dual FMA units (theoretical 16 FLOPS/cycle)
    float8 sum8 = (float8)(0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f, 0.0f);
#else
    float sum = 0.0f;
#endif

    const int num_tiles = (K + TILE_SIZE - 1) / TILE_SIZE;

#ifdef USE_PREFETCHING
    // Double-buffered LDS for advanced prefetching
    __local float A_tile[2][TILE_SIZE][TILE_SIZE + LDS_PADDING];
    __local float B_tile[2][TILE_SIZE][TILE_SIZE + LDS_PADDING];

    // Prefetch first tile
    int current_buffer = 0;
    {{
        const int a_row = group_y * TILE_SIZE + local_y;
        const int a_col = current_buffer * TILE_SIZE + local_x;
        const int b_row = current_buffer * TILE_SIZE + local_y;
        const int b_col = group_x * TILE_SIZE + local_x;

        if (a_row < M && a_col < K) {{
            A_tile[current_buffer][local_y][local_x] = A[a_row * K + a_col];
        }} else {{
            A_tile[current_buffer][local_y][local_x] = 0.0f;
        }}

        if (b_row < K && b_col < N) {{
            B_tile[current_buffer][local_y][local_x] = B[b_row * N + b_col];
        }} else {{
            B_tile[current_buffer][local_y][local_x] = 0.0f;
        }}
    }}

    barrier(CLK_LOCAL_MEM_FENCE);

    // Main computation loop with prefetching
    for (int t = 0; t < num_tiles; t++) {{
        int next_buffer = (current_buffer + 1) % 2;

        // Prefetch next tile asynchronously
        if (t + 1 < num_tiles) {{
            const int a_row_next = group_y * TILE_SIZE + local_y;
            const int a_col_next = (t + 1) * TILE_SIZE + local_x;
            const int b_row_next = (t + 1) * TILE_SIZE + local_y;
            const int b_col_next = group_x * TILE_SIZE + local_x;

            if (a_row_next < M && a_col_next < K) {{
                A_tile[next_buffer][local_y][local_x] = A[a_row_next * K + a_col_next];
            }} else {{
                A_tile[next_buffer][local_y][local_x] = 0.0f;
            }}

            if (b_row_next < K && b_col_next < N) {{
                B_tile[next_buffer][local_y][local_x] = B[b_row_next * N + b_col_next];
            }} else {{
                B_tile[next_buffer][local_y][local_x] = 0.0f;
            }}
        }}

        // Compute current tile
#ifdef USE_FLOAT8
        // GCN 4.0: Float8 operations targeting dual FMA pipes
        #pragma unroll 2  // Unroll for float8 operations
        for (int k = 0; k < TILE_SIZE; k += 8) {{
            // Load 8 consecutive values (bank conflict free due to padding)
            float8 a_vec = (float8)(
                A_tile[current_buffer][local_y][k],
                A_tile[current_buffer][local_y][k+1],
                A_tile[current_buffer][local_y][k+2],
                A_tile[current_buffer][local_y][k+3],
                A_tile[current_buffer][local_y][k+4],
                A_tile[current_buffer][local_y][k+5],
                A_tile[current_buffer][local_y][k+6],
                A_tile[current_buffer][local_y][k+7]
            );

            float8 b_vec = (float8)(
                B_tile[current_buffer][k][local_x],
                B_tile[current_buffer][k+1][local_x],
                B_tile[current_buffer][k+2][local_x],
                B_tile[current_buffer][k+3][local_x],
                B_tile[current_buffer][k+4][local_x],
                B_tile[current_buffer][k+5][local_x],
                B_tile[current_buffer][k+6][local_x],
                B_tile[current_buffer][k+7][local_x]
            );

            // Dual FMA operations (16 FLOPS per cycle theoretical)
            sum8 = mad(a_vec, b_vec, sum8);
        }}
#else
        // Standard float operations with advanced unrolling
        #pragma unroll 8
        for (int k = 0; k < TILE_SIZE; k++) {{
            float a_val = A_tile[current_buffer][local_y][k];
            float b_val = B_tile[current_buffer][k][local_x];
            sum = mad(a_val, b_val, sum);
        }}
#endif

        // Switch buffers
        current_buffer = next_buffer;
        barrier(CLK_LOCAL_MEM_FENCE);
    }}

#else
    // Single-buffered LDS (fallback for comparison)
    __local float A_tile[TILE_SIZE][TILE_SIZE + LDS_PADDING];
    __local float B_tile[TILE_SIZE][TILE_SIZE + LDS_PADDING];

    for (int t = 0; t < num_tiles; t++) {{
        // Load tile
        const int a_row = group_y * TILE_SIZE + local_y;
        const int a_col = t * TILE_SIZE + local_x;
        const int b_row = t * TILE_SIZE + local_y;
        const int b_col = group_x * TILE_SIZE + local_x;

        if (a_row < M && a_col < K) {{
            A_tile[local_y][local_x] = A[a_row * K + a_col];
        }} else {{
            A_tile[local_y][local_x] = 0.0f;
        }}

        if (b_row < K && b_col < N) {{
            B_tile[local_y][local_x] = B[b_row * N + b_col];
        }} else {{
            B_tile[local_y][local_x] = 0.0f;
        }}

        barrier(CLK_LOCAL_MEM_FENCE);

#ifdef USE_FLOAT8
        // Float8 operations without prefetching
        #pragma unroll 2
        for (int k = 0; k < TILE_SIZE; k += 8) {{
            float8 a_vec = (float8)(
                A_tile[local_y][k], A_tile[local_y][k+1], A_tile[local_y][k+2], A_tile[local_y][k+3],
                A_tile[local_y][k+4], A_tile[local_y][k+5], A_tile[local_y][k+6], A_tile[local_y][k+7]
            );
            float8 b_vec = (float8)(
                B_tile[k][local_x], B_tile[k+1][local_x], B_tile[k+2][local_x], B_tile[k+3][local_x],
                B_tile[k+4][local_x], B_tile[k+5][local_x], B_tile[k+6][local_x], B_tile[k+7][local_x]
            );
            sum8 = mad(a_vec, b_vec, sum8);
        }}
#else
        #pragma unroll 8
        for (int k = 0; k < TILE_SIZE; k++) {{
            float a_val = A_tile[local_y][k];
            float b_val = B_tile[k][local_x];
            sum = mad(a_val, b_val, sum);
        }}
#endif

        barrier(CLK_LOCAL_MEM_FENCE);
    }}
#endif

    // Write results with coalesced access
    const int c_idx = global_y * N + global_x;

#ifdef USE_FLOAT8
    // Convert float8 result to scalar
    float final_sum = sum8.s0 + sum8.s1 + sum8.s2 + sum8.s3 +
                     sum8.s4 + sum8.s5 + sum8.s6 + sum8.s7;
#else
    float final_sum = sum;
#endif

    // Apply alpha/beta scaling
    float c_old = (beta != 0.0f) ? C[c_idx] : 0.0f;
    C[c_idx] = alpha * final_sum + beta * c_old;
}}
"""
        return kernel_code

class GCN4DeepOptimizedExecutor:
    """Executor para kernel GCN 4.0 deeply optimized."""

    def __init__(self, config: Optional[GCN4DeepOptimizationConfig] = None):
        self.config = config or GCN4DeepOptimizationConfig()
        self.context = None
        self.queue = None
        self.program = None
        self.kernel = None

        if PYOPENCL_AVAILABLE:
            self._initialize_opencl()

    def _initialize_opencl(self):
        """Initialize OpenCL context and compile kernel."""
        try:
            platforms = cl.get_platforms()
            amd_platform = next((p for p in platforms if 'AMD' in p.name), platforms[0])
            devices = amd_platform.get_devices(device_type=cl.device_type.GPU)

            if not devices:
                raise RuntimeError("No GPU devices found")

            self.device = devices[0]
            logger.info(f"Using device: {self.device.name}")

            self.context = cl.Context([self.device])
            self.queue = cl.CommandQueue(self.context, properties=cl.command_queue_properties.PROFILING_ENABLE)

            # Compile kernel
            kernel_source = GCN4DeepOptimizedKernel.create_kernel_source(self.config)
            compiler_options = self.config.get_compiler_options()

            logger.info("Compiling GCN 4.0 deep optimized kernel...")
            logger.info(f"Compiler options: {compiler_options}")

            self.program = cl.Program(self.context, kernel_source).build(options=compiler_options)
            self.kernel = self.program.gemm_gcn4_deep_optimized

            logger.info("GCN 4.0 deep optimized kernel compiled successfully")

        except Exception as e:
            logger.error(f"OpenCL initialization failed: {e}")
            raise

    def gemm(self, A: np.ndarray, B: np.ndarray,
             C: Optional[np.ndarray] = None,
             alpha: float = 1.0, beta: float = 0.0) -> Tuple[np.ndarray, float]:
        """
        Execute deep optimized GCN 4.0 GEMM: C = alpha * A @ B + beta * C
        """
        if not PYOPENCL_AVAILABLE or self.kernel is None:
            # Fallback to NumPy
            start_time = time.time()
            if C is None:
                C = np.zeros((A.shape[0], B.shape[1]), dtype=np.float32)
            C = alpha * (A @ B) + beta * C
            end_time = time.time()
            return C, (end_time - start_time) * 1000

        return self._execute_gpu(A, B, C, alpha, beta)

    def _execute_gpu(self, A: np.ndarray, B: np.ndarray,
                    C: Optional[np.ndarray], alpha: float, beta: float) -> Tuple[np.ndarray, float]:
        """Execute GEMM on GPU."""
        M, K = A.shape
        K2, N = B.shape
        assert K == K2, f"Matrix dimension mismatch: A {A.shape}, B {B.shape}"

        if C is None:
            C = np.zeros((M, N), dtype=np.float32)
        else:
            assert C.shape == (M, N), f"C shape mismatch: expected {(M, N)}, got {C.shape}"

        # Create OpenCL buffers
        mf = cl.mem_flags
        A_buf = cl.Buffer(self.context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=A.astype(np.float32))
        B_buf = cl.Buffer(self.context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=B.astype(np.float32))
        C_buf = cl.Buffer(self.context, mf.READ_WRITE | mf.COPY_HOST_PTR, hostbuf=C)

        # Set kernel arguments
        self.kernel.set_args(
            np.int32(M), np.int32(N), np.int32(K),
            np.float32(alpha), np.float32(beta),
            A_buf, B_buf, C_buf
        )

        # Work group sizing
        wg_x, wg_y = self.config.workgroup_size
        global_x = ((N + wg_x - 1) // wg_x) * wg_x
        global_y = ((M + wg_y - 1) // wg_y) * wg_y
        global_size = (global_x, global_y)
        local_size = (wg_x, wg_y)

        # Execute kernel
        event = cl.enqueue_nd_range_kernel(self.queue, self.kernel, global_size, local_size)
        event.wait()

        # Get execution time
        exec_time_ms = (event.profile.end - event.profile.start) * 1e-6

        # Read result
        result = np.empty_like(C)
        cl.enqueue_copy(self.queue, result, C_buf).wait()

        return result, exec_time_ms

class GCN4DeepOptimizationBenchmark:
    """Benchmark completo para optimizaciones profundas de GCN 4.0."""

    def __init__(self):
        self.baseline_executor = GCN4RefinedGEMMExecutor()
        self.deep_executors = {}

    def create_optimization_configs(self) -> List[GCN4DeepOptimizationConfig]:
        """Crear configuraciones de optimizaci√≥n para testing."""
        configs = []

        # Configuraci√≥n base (similar a refined)
        configs.append(GCN4DeepOptimizationConfig(
            use_float8=False, use_prefetching=False, wavefront_optimization=False
        ))

        # Float8 operations
        configs.append(GCN4DeepOptimizationConfig(
            use_float8=True, use_prefetching=False, wavefront_optimization=False
        ))

        # Advanced prefetching
        configs.append(GCN4DeepOptimizationConfig(
            use_float8=False, use_prefetching=True, wavefront_optimization=False
        ))

        # Full optimization (float8 + prefetching + wavefront opt)
        configs.append(GCN4DeepOptimizationConfig(
            use_float8=True, use_prefetching=True, wavefront_optimization=True
        ))

        return configs

    def benchmark_configuration(self, config: GCN4DeepOptimizationConfig,
                              matrix_size: int, num_runs: int = 5) -> Dict[str, Any]:
        """Benchmark una configuraci√≥n espec√≠fica."""
        logger.info(f"Benchmarking config (float8={config.use_float8}, "
                   f"prefetch={config.use_prefetching}, wavefront={config.wavefront_optimization}) "
                   f"on {matrix_size}x{matrix_size}")

        try:
            executor = GCN4DeepOptimizedExecutor(config)

            # Create test matrices
            A = np.random.randn(matrix_size, matrix_size).astype(np.float32)
            B = np.random.randn(matrix_size, matrix_size).astype(np.float32)
            C_ref = A @ B

            times = []
            errors = []

            # Warmup
            for _ in range(2):
                _ = executor.gemm(A, B)

            # Benchmark runs
            for _ in range(num_runs):
                C_result, exec_time = executor.gemm(A, B)
                times.append(exec_time)

                # Check accuracy
                error = np.max(np.abs(C_result - C_ref)) / np.max(np.abs(C_ref))
                errors.append(error)

            # Calculate statistics
            avg_time = np.mean(times)
            gflops = (2 * matrix_size**3) / (avg_time * 1e-3) / 1e9

            return {
                'matrix_size': matrix_size,
                'config': {
                    'use_float8': config.use_float8,
                    'use_prefetching': config.use_prefetching,
                    'wavefront_optimization': config.wavefront_optimization
                },
                'avg_time_ms': avg_time,
                'min_time_ms': np.min(times),
                'max_time_ms': np.max(times),
                'std_time_ms': np.std(times),
                'gflops': gflops,
                'avg_error': np.mean(errors),
                'max_error': np.max(errors),
                'status': 'success'
            }

        except Exception as e:
            logger.error(f"Failed to benchmark configuration: {e}")
            return {
                'matrix_size': matrix_size,
                'config': {
                    'use_float8': config.use_float8,
                    'use_prefetching': config.use_prefetching,
                    'wavefront_optimization': config.wavefront_optimization
                },
                'status': 'failed',
                'error': str(e)
            }

    def run_comprehensive_benchmark(self, sizes: List[int] = None) -> Dict[str, Any]:
        """Ejecutar benchmark completo de optimizaciones profundas."""
        if sizes is None:
            sizes = [1024, 2048]  # Focus on sizes where we need improvement

        logger.info("üöÄ PHASE 5: GCN 4.0 Deep Optimization Comprehensive Benchmark")
        logger.info("Target: 950-1050 GFLOPS through advanced architectural exploitation")

        configs = self.create_optimization_configs()
        results = {}

        # First, benchmark baseline (current GCN4 refined)
        logger.info("\nüìä Benchmarking baseline (GCN4 Refined)...")
        baseline_results = {}
        for size in sizes:
            result = self.benchmark_configuration(configs[0], size)  # Baseline config
            baseline_results[f"{size}x{size}"] = result
        results['baseline'] = baseline_results

        # Benchmark optimized configurations
        for i, config in enumerate(configs[1:], 1):
            config_name = f"config_{i}"
            logger.info(f"\nüîß Benchmarking {config_name}...")
            config_results = {}

            for size in sizes:
                result = self.benchmark_configuration(config, size)
                config_results[f"{size}x{size}"] = result

            results[config_name] = config_results

        return results

    def analyze_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Analizar resultados del benchmark."""
        analysis = {
            'summary': {},
            'best_configuration': {},
            'performance_analysis': {},
            'recommendations': []
        }

        # Find best performing configuration
        best_gflops = 0
        best_config = None

        for config_name, config_results in results.items():
            if config_name == 'baseline':
                continue

            for size_key, result in config_results.items():
                if result.get('status') == 'success' and result['gflops'] > best_gflops:
                    best_gflops = result['gflops']
                    best_config = (config_name, size_key, result)

        if best_config:
            analysis['best_configuration'] = {
                'config_name': best_config[0],
                'matrix_size': best_config[1],
                'gflops': best_config[2]['gflops'],
                'improvement_over_baseline': 0  # Will calculate
            }

        # Calculate improvements
        if 'baseline' in results and best_config:
            baseline_gflops = results['baseline'][best_config[1]]['gflops']
            improvement = (best_config[2]['gflops'] - baseline_gflops) / baseline_gflops * 100
            analysis['best_configuration']['improvement_over_baseline'] = improvement

        # Overall assessment
        target_achieved = best_gflops >= 950 if best_config else False

        analysis['summary'] = {
            'target_gflops': 950,
            'best_gflops_achieved': best_gflops,
            'target_achieved': target_achieved,
            'status': 'SUCCESS' if target_achieved else 'NEEDS_IMPROVEMENT'
        }

        # Recommendations
        if not target_achieved:
            analysis['recommendations'].append("Further optimization needed to reach 950 GFLOPS target")
            analysis['recommendations'].append("Consider additional GCN 4.0 ISA-specific optimizations")
            analysis['recommendations'].append("Evaluate memory controller scheduling optimizations")

        return analysis

    def save_results(self, results: Dict[str, Any], analysis: Dict[str, Any],
                    filename: str = None) -> str:
        """Guardar resultados del benchmark."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"gcn4_deep_optimization_benchmark_{timestamp}.json"

        results_dir = Path(__file__).parent / 'results'
        results_dir.mkdir(exist_ok=True)
        filepath = results_dir / filename

        output_data = {
            'benchmark_info': {
                'phase': 'Phase 5 - GCN 4.0 Deep Optimization',
                'target': '950-1050 GFLOPS',
                'timestamp': datetime.now().isoformat(),
                'description': 'Comprehensive benchmark of advanced GCN 4.0 optimizations'
            },
            'results': results,
            'analysis': analysis
        }

        with open(filepath, 'w') as f:
            json.dump(output_data, f, indent=2, default=str)

        logger.info(f"Results saved to: {filepath}")
        return str(filepath)

    def print_summary(self, results: Dict[str, Any], analysis: Dict[str, Any]):
        """Imprimir resumen del benchmark."""
        print("\n" + "="*80)
        print("PHASE 5: GCN 4.0 DEEP OPTIMIZATION BENCHMARK SUMMARY")
        print("="*80)

        print(f"\nüéØ Target: {analysis['summary']['target_gflops']} GFLOPS")
        print(f"Best Achieved: {analysis['summary']['best_gflops_achieved']:.1f} GFLOPS")
        print(f"Status: {analysis['summary']['status']}")

        if analysis['best_configuration']:
            bc = analysis['best_configuration']
            print("\nüèÜ Best Configuration:")
            print(f"  Config: {bc['config_name']}")
            print(f"  Matrix Size: {bc['matrix_size']}")
            print(f"  GFLOPS: {bc['gflops']:.1f}")
            print(f"  Improvement: {bc['improvement_over_baseline']:+.1f}%")

        if analysis['recommendations']:
            print("\nüí° Recommendations:")
            for rec in analysis['recommendations']:
                print(f"  ‚Ä¢ {rec}")

def main():
    """Main benchmark execution."""
    benchmark = GCN4DeepOptimizationBenchmark()

    # Run comprehensive benchmark
    results = benchmark.run_comprehensive_benchmark()

    # Analyze results
    analysis = benchmark.analyze_results(results)

    # Save and print results
    results_file = benchmark.save_results(results, analysis)
    benchmark.print_summary(results, analysis)

    return results_file

if __name__ == "__main__":
    main()
